<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157941252-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-157941252-1');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"/>
  <meta http-equiv="Pragma" content="no-cache"/>
  <meta http-equiv="Expires" content="0"/>

  <title>Hojoon Lee</title>

  <meta name="author" content="Hojoon Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/personal_round.png">

</head>

<body>
  <div class="container">
    <div class="row" style="margin-top: 10px;">
      <div class="col-sm-4 name-column" style="min-width: 266px;">
        <p style="text-align:center">
          <name>Hojoon Lee</name>
        </p>
      </div>
      <div class="col-sm-8 name-column text-right" style="min-width: 266px; margin-top: 10px">
        <p style="text-align:right">
            <a href="https://davian.kaist.ac.kr/"><img src="pictures/davian_logo.png" alt="logo_uni_tue" class="institute-logo-small"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
            <a href="https://gsai.kaist.ac.kr/?lang=eng/"><img src="pictures/kaistai_logo.png" alt="logo_uni_tue" class="institute-logo-medium"></a>
        </p>
      </div>
    </div>
    <div class="row common-rows">

      <div class="col-xs-12 col-sm-8 personal-column">
        <p> 
          Hello! I am a Ph.D student at KAIST AI, advised by <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>. <br> 
        </p>
        <p>  
          I am interested in creating intelligent agents that can continually learn, adapt, and generalize in dynamic environments. 
          To do so, I am interested in self-supervised learning, reinforcement learning, and its applications to gaming and robotics.
        </p>
        <p>
          Previously, I received M.S at KAIST, and B.S at Korea University. 
          During the 1st half of 2024, I interned in the RL team at Sony AI, mentored by 
          <a href="https://takuseno.github.io/">Takuma Seno</a> and 
          <a href="https://kausubbu.github.io/">Kaushik Subramanian</a>. 
          In winter 2022, I interned at RL team at Kakao Enterprise, working closely with 
          <a href="https://github.com/Kyushik">Kyushik Min</a>. 
          In summer 2020, I interned at RL team at Neowiz Games, focusing on turn-based strategy game, 
          <a href="https://www.browndust.app/ko">BrownDust</a>.
        </p>

        <p style="text-align:center">
          <a href="mailto:joonleesky@kaist.ac.kr">Email</a> &nbsp/&nbsp
          <a href="data/hojoonlee202405cv.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=g0R5CDMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/hojoon-lee-6872a4222/">LinkedIn</a> &nbsp/&nbsp
          <a href="https://github.com/joonleesky/">Github</a>
        </p>

      </div>
      <div class="col-xs-12 col-sm-4 personal-column" style="margin-top: 30px">
        <img alt="profile photo" src="pictures/profile.png" class="personal-photo">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h4>News</h4>
    </div>
    <div class="row">
      <p>
        <ul>
          <li><b>02-08.2024</b>. I will be joining a Gran Turismo team at Sony AI, Tokyo, as a research intern.</li>
          <li><b>05.2024.</b> 3 RL papers accepted @ ICML'24: <a href="#icml2024hnt">Hare & Tortoise</a>, <a href="#icml2024atari-pb">ATARI-PB</a>, and <a href="#icml2024coin">CoIN</a>.
          <li><b>09.2023.</b> 2 RL papers accepted @ NeurIPS'23: <a href="#neurips2023plastic">PLASTIC</a> and <a href="#neurips2023disco-dance">DISCO-DANCE</a>.
        </ul>
      </p>
    </div>
  </div>

  <br>
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Publications</h4>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src="pictures/preprint2024dodont.png" alt="preprint2024dodont" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span>
        <br>
            <papertitle>
                Do’s and Don’ts: Learning Desirable Skills with Instruction Videos
            </papertitle>
        <br>
        <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
        Byungkun Lee,
        <strong>Hojoon Lee</strong>,
        Dongyoon Hwang,
        Donghu Kim,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
        <br>
        <em>Preprint</em>.
        <br><br>
        <p style="margin-top: -1%;"> 
            We present DoDont, a skill discovery algorithm that learns diverse behaviors 
            while following the behaviors in "do" videos while avoiding the behaviors in "don't" videos.
        </p>
      </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src="pictures/icml2024hnt.png" alt="icml2024hnt" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span>
        <br>
        <a href="data/icml2024hnt.pdf" id="icml2024hnt">
          <papertitle>
            Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks
          </papertitle>
        </a>
        <br>
        <strong>Hojoon Lee</strong>,
        Hyeonseo Cho,
        <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
        Donghu Kim,
        Dugki Min,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
        <a href="https://clarelyle.com/">Clare Lyle</a>.
        <br>
        <em>ICML'24</em>.
        <br><br>
        <p style="margin-top: -1%;"> 
            To allow the network to continually adapt and generalize, we introduce Hare and Tortoise architecture, 
            inspired by the complementary learning system of the human brain.
        </p>
      </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/icml2024atari-pb.png" alt="icml2024atari-pb" class="paper-images">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
          <span style="background-color:#e2c7e5">Reinforcement Learning</span>
          <span style="background-color:#ffdac1">Pre-training</span>
          <br>
            <papertitle>
              ATARI-PB: Investigating Pre-Training Objectives for Generalization in Pixel-Based RL
            </papertitle>
          <br>
          Donghu Kim*,
          <strong>Hojoon Lee*</strong>,
          Kyungmin Lee*,
          Dongyoon Hwang,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
          <br>
          <em>ICML'24</em>.
          <br><br>
          <p style="margin-top: -1%;"> 
            We investigate which pre-training objectives are beneficial for in-distribution, near-out-of-distribution, and far-out-of-distribution generalization in visual reinforcement learning.
          </p>
        </div>
      </div>
    
    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/icml2024coin.png" alt="icml2024coin" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#f1f1b2">Adaptation</span>
        <br>
        <papertitle>
            CoIN: A Simple Convolution INjector for Vision Transformer. Towards Effective Adaptation in Visuo-Motor Control
        </papertitle>
        <br>
        Donyoon Hwang*, 
        Byungkun Lee*,
        <strong>Hojoon Lee</strong>,
        <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>ICML'24</em>.
        <br><br>
        <p style="margin-top: -1%;"> 
            Introducing an add-on convolution module for pre-trained ViT models, 
            enhancing adaptability for vision-based motor control with injecting locality and translation equivariant biases.
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/neurips2023plastic.png" alt="neurips2023plastic" class="paper-images" style="width:92%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span>
        <br>
        <a href="https://arxiv.org/abs/2306.10711" id="neurips2023plastic">
        <papertitle>
            PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning
        </papertitle>
        </a>
        <br>
        <strong>Hojoon Lee*</strong>, 
        <a href="https://hanseuljo.github.io">Hanseul Cho*</a>, 
        <a href="https://mynsng.github.io/">Hyunseung Kim*</a>, 
        Daehoon Gwak, 
        Joonkee Kim, 
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
        <a href="https://fbsqkd.github.io/">Se-Young Yun</a>,
        <a href="https://chulheeyun.github.io/">Chulhee Yun</a>.
        <br>
        <em>NeurIPS'23</em>.
        <br>
        <a href="https://arxiv.org/abs/2306.10711">arXiv</a> /
        <a href="https://github.com/dojeon-ai/plastic">code</a> /
        <a href="https://drive.google.com/file/d/1-QeWhom9l7mUt3m7zJV-_DIGMtL7F2Cq/view?usp=sharing">slide</a> /
        <a href="https://drive.google.com/file/d/1-OTP_-rw2x-csjsJ9jH7utuHw9zDxsJc/view?usp=sharing">poster</a> /
        <a href="data/neurips2023plastic.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
            For sample-efficient RL, the agent needs to quickly adapt to various inputs (input plasticity) and outputs (label plasticity). 
            We present PLASTIC, which maintains both input and label plasticity by identifying smooth local minima and preserving gradient flow. 
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/neurips2023disco-dance.png" alt="neurips2023disco-dance" class="paper-images" style="width:90%; margin-left:10%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span>
        <br>
        <a href="https://arxiv.org/abs/2310.20178v2" id="neurips2023disco-dance">
        <papertitle>
            DISCO-DANCE: Learning to Discover Skills through Guidance
        </papertitle>
        </a>
        <br>
        <a href="https://mynsng.github.io/">Hyunseung Kim*</a>, 
        Byungkun Lee*,
        <strong>Hojoon Lee</strong>, 
        Dongyoon Hwang,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>NeurIPS'23</em>.
        <br>
        <a href="https://mynsng.github.io/discodance/">project page</a> /
        <a href="https://arxiv.org/abs/2310.20178">arXiv</a> /
        <a href="https://github.com/dojeon-ai/discodance">code</a> /
        <a href="data/neurips2023disco-dance.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
        We introduce DISCO-DANCE, a Skill Discovery algorithm focused on learning diverse, task-agnostic behaviors. 
        DISCO-DANCE addresses the common limitation of exploration in skill discovery algorithms through explicit guidance.
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/icml2023simtpr.png" alt="icml2023simtpr" class="paper-images" style="margin-left:5%; width:98%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ffdac1">Pre-training</span>
        <br>
        <a href="https://arxiv.org/abs/2306.05637" id="icml2023simtpr">
        <papertitle>
            SimTPR: On the Importance of Feature Decorrelation for Unsupervised Representation Learning for Reinforcement Learning
        </papertitle>
        </a>
        <br>
        <strong>Hojoon Lee</strong>,
        Koanho Lee, 
        Dongyoon Hwang, 
        Hyunho Lee, 
        Byungkun Lee, 
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>ICML'23</em>.
        <br>
        <a href="https://arxiv.org/abs/2306.05637">arXiv</a> /
        <a href="https://github.com/dojeon-ai/SimTPR">code</a> /
        <a href="https://drive.google.com/file/d/1FPJHtd3uY54P2iOoPBrnt8jD-ud6nF6G/view?usp=sharing">poster</a> /
        <a href="data/icml2023simtpr.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
        We present a visual pre-training algorithm grounded in self-predictive learning principles tailored for reinforcement learning.
        </p>
    </div>
    </div>


    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/cikm2023strap.png" alt="cikm2023strap" class="paper-images" style="width: 90%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#C9D3D8">Data Mining</span>
        <br>
        <a href="https://dl.acm.org/doi/10.1145/3583780.3615168" id="cikm2023strap">
        <papertitle>
            ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal 
        </papertitle>
        </a>
        <br>
        <strong>Hojoon Lee*</strong>,
        Hawon Jung*,
        Byungkun Lee*, 
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>CIKM'23 (short)</em>.
        <br>
        <a href="https://arxiv.org/abs/2308.10609v1">arXiv</a> /
        <a href="https://github.com/dojeon-ai/STRAP">code</a> /
        <a href="https://drive.google.com/file/d/1ht5I6-PQmzlVzF-1YQCkBO1XcrVGbjk7/view?usp=sharing">poster</a> /
        <a href="data/cikm2023strap.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
        We construct a real estate appraisal framework that integrates spatial and temporal aspects, 
        validated using a dataset of 3.6M real estate transactions in South Korea from 2016 to 2020.          
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/sigir2022irs.png" alt="sigir2022irs" class="paper-images" style="margin-left:5%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531869" id="sigir2022irs">
            <papertitle>
                Towards Validating Long-Term User Feedbacks in Interactive Recommender System
            </papertitle>
            </a>
            <br>
            <strong>Hojoon Lee</strong>,
            Dongyoon Hwang,
            Kyushik Min,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>SIGIR'22 (short), <b>Best Honorable Mention Award</b></em>.
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531869">arXiv</a> /
            <a href="https://drive.google.com/file/d/13PEGDMrfZaG-PcCp0tx-A_L_2E1MKqQm/view?usp=sharing">poster</a> /
            <a href="data/sigir2022irs.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">              
                Through validating the long-term impact of user feedback in MovieLens and Amazon Review datasets, 
                we've discovered that these datasets are inadequate for evaluating reinforcement learning-based interactive recommender systems.        
            </p>
        </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/www2022draftrec.png" alt="www2022draftrec" class="paper-images" style="margin-left:8%; width:95%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <span style="background-color:#c9d2fe">Game</span>
            <br>
            <a href="https://dl.acm.org/doi/10.1145/3485447.3512278" id="www2022draftrec">
            <papertitle>
                DraftRec: Personalized Draft Recommendation for Winning in MOBA Games
            </papertitle>
            </a>
            <br>
            <strong>Hojoon Lee*</strong>,
            Dongyoon Hwang*,
            <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
            Byungkun Lee, 
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>WWW'22</em>.
            <br>
            <a href="https://arxiv.org/abs/2204.12750">arXiv</a> /
            <a href="https://github.com/dojeon-ai/DraftRec">code</a> /
            <a href="https://drive.google.com/file/d/15L2ZqVutI3xjwJXq9NGbizSZbNsQEXOK/view?usp=sharing">poster</a> /
            <a href="data/www2022draftrec.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">                         
                We gathered data from 280,000 matches played by the top 0.3% rank players in Korea for League of Legends. 
                From this, we developed DraftRec, a personalized champion recommendation system aimed at maximizing players' win rates.   
            </p>
        </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/cog2022gunshot.png" alt="cog2022gunshot" class="paper-images" style="margin-left:3%;">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#c9d2fe">Game</span>
            <br>
            <a href="https://arxiv.org/abs/2210.05917" id="cog2022gunshot">
            <papertitle>
                Enemy Spotted: In-game Gun Sound Dataset for Gunshot Classification and Localization
            </papertitle>
            </a>
            <br>
            Junwoo Park, 
            Youngwoo Cho, 
            Gyuhyeon Sim, 
            <strong>Hojoon Lee</strong>,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>COG'22</em>.
            <br>
            <a href="https://arxiv.org/abs/2210.05917">arXiv</a> /
            <a href="data/cog2022gunshot.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">                         
                We collected a gunshot sound dataset from PlayerUnknown's Battlegrounds (PUBG). 
                Using this data, we developed a gunshot localization model that can be applied to real-world scenarios.
            </p>
        </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/korea2019browndust.png" alt="korea2019browndust" class="paper-images" style="margin-left:3%;">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <span style="background-color:#c9d2fe">Game</span>
            <br>
            <a href="data/korea2019browndust.pdf" id="korea2019browndust">
            <papertitle>
                Conquering a rule-changing game with action-releavance aware Alpha-Zero
            </papertitle>
            </a>
            <br>
            <strong>Hojoon Lee</strong>,
            Dongyoon Hwang,
            Jeesoo Woo,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>Preprint'19</em>.
            <br>
            <a href="data/korea2019browndust.pdf">poster</a>
            <br><br>
            <p style="margin-top: -1%;">                         
                We've developed an AI agent for the turn-based strategy game BrownDust. 
                To enhance learning efficiency, we've designed feature representations and specified architectures for embedding the game characters.
            </p>
        </div>
    </div>

  <br>
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Other activities</h4>
    </div>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/review.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Reviewing activities
        </papertitle>
        <br>
        <ul>
          <li>Serving as a reviewer for NeurIPS'23, ICML'24, ICLR'24.</li>
        </ul>
      </div>
    </div>

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/award.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Awards
        </papertitle>
        <br>
        <ul>
          <li>Travel Award ($3,000 as awards), Crevisse Partners, 2023.</li>
          <li>SIGIR Best Short Paper Honorable Mention, 2022.</li>
          <li>Korea Government Full Scholarship ($10,000 per year), 2020, 2021.</li>
          <li>Silver Prize ($2,000 as awards), Korea University Graduation Project, 2019.</li>
          <li>College Scholarship ($4,000 as awards), Seongnam Scholarship Foundation, 2017.</li>
          <li><a href="https://www.army.mil/article/180976/area_ii_chapter_sergeant_audie_murphy_clubgeneral_paik_leadership_award_induction_ceremony">General Paik Sun Yup Leadership Award</a>
            , LTG Thomas.S.Vandal, U.S Army, 2017.</li>
        </ul>
      </div>
    </div>
    <br>

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/talk.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9">
        <papertitle>Talks
        </papertitle>
        <br>
        <ul>
          <li>
            <a href="data/plastic2024talk.pdf">
              Towards Plastic Neural Network
            </a>.
            Sony AI, Tokyo, March 2024.
          </li>
          <li>
            <a href="data/plastic2024talk.pdf">
                Towards Plastic Neural Network
            </a>.
            Konkuk University DMIS Lab, Seoul, Feb 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            RL Korea, Seoul, Jan 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            Crevisse Partners, Seoul, Dec 2023.</li>
        </ul>
      </div>
    </div>
  </div>


  <div class="container">
    <div class="row">
      <div class="col">
        <p style="text-align:right;font-size:small;">
          Template based on <a href="https://jonbarron.info/">Jon Barron's website</a>.
        </p>
      </div>
    </div>
  </div>
</body>

</html>
